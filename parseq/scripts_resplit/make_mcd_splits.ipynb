{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parseq.datasets import CFQDatasetLoader\n",
    "from parseq.scripts_resplit.resplit_cfq import FrequencyDistribution, DivergenceComputer\n",
    "import random, json\n",
    "from typing import List\n",
    "from parseq.grammar import taglisp_to_tree\n",
    "from nltk import Tree\n",
    "from tqdm import tqdm\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFQDatasetLoader: make data\n",
      "CFQDatasetLoader: make data in 0.0 sec\n",
      "loading split 'mcd1'\n",
      "splitting off a random 10% of 'train' for 'iidvalid' using seed 42\n",
      "doing 'train'\n",
      "doing 'test'\n",
      "doing 'iidvalid'\n",
      "doing 'oodvalid'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86169/86169 [00:23<00:00, 3691.63it/s]\n",
      "100%|██████████| 11968/11968 [00:03<00:00, 3150.39it/s]\n",
      "100%|██████████| 9574/9574 [00:02<00:00, 3714.33it/s]\n",
      "100%|██████████| 11968/11968 [00:03<00:00, 3137.24it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = CFQDatasetLoader().load(split=\"mcd1/modent\", keepids=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "xs = ds.examples\n",
    "random.shuffle(xs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_approx_chernoff_change_twoway(comps, dist1:FrequencyDistribution, dist2:FrequencyDistribution, alpha=0.5):\n",
    "    cchange1 = 0\n",
    "    cchange2 = 0\n",
    "    for comp in comps:\n",
    "        cchange1 += (((dist1[comp] + 1)/dist1.total) ** alpha - dist1(comp) ** alpha) * (dist2(comp) ** (1-alpha))\n",
    "        cchange2 += (dist1(comp) ** alpha) * (((dist2[comp] + 1)/dist2.total) ** (1-alpha) - dist2(comp) ** (1-alpha))\n",
    "    return cchange1, cchange2\n",
    "\n",
    "def compute_approx_chernoff_change(comps, traindist:FrequencyDistribution, validdist:FrequencyDistribution, testdist:FrequencyDistribution, alpha=0.1):\n",
    "    trainchange = 0   # change in total weighted chernoff coeff if example is assigned to train\n",
    "    validchange = 0   # \"\" \"\" if assigned to valid\n",
    "    testchange = 0    # \"\" \"\" \"\" test\n",
    "    for comp in comps:\n",
    "        trainchange += (((traindist[comp] + 1)/(traindist.total + 1)) ** alpha - traindist(comp) ** alpha) * (testdist(comp) ** (1-alpha))\n",
    "        trainchange += (((traindist[comp] + 1)/(traindist.total + 1)) ** alpha - traindist(comp) ** alpha) * (validdist(comp) ** (1-alpha))\n",
    "        validchange += (((validdist[comp] + 1)/(validdist.total + 1)) ** alpha - validdist(comp) ** alpha) * (testdist(comp) ** (1-alpha))\n",
    "        validchange += (traindist(comp) ** alpha) * (((validdist[comp] + 1)/(validdist.total+1)) ** (1-alpha) - validdist(comp) ** (1-alpha))\n",
    "        testchange += (traindist(comp) ** alpha) * (((testdist[comp] + 1)/(testdist.total+1)) ** (1-alpha) - testdist(comp) ** (1-alpha))\n",
    "        testchange += (validdist(comp) ** alpha) * (((testdist[comp] + 1)/(testdist.total+1)) ** (1-alpha) - testdist(comp) ** (1-alpha))\n",
    "    return trainchange, validchange, testchange\n",
    "\n",
    "def compute_true_chernoff_chagne(comps, traindist:FrequencyDistribution, validdist:FrequencyDistribution, testdist:FrequencyDistribution, alpha=0.1):\n",
    "    dc = DivergenceComputer()\n",
    "    _traindist = FrequencyDistribution()\n",
    "    _traindist._counts = copy(traindist._counts)\n",
    "    _traindist.total = traindist.total\n",
    "\n",
    "    _validdist = FrequencyDistribution()\n",
    "    _validdist._counts = copy(validdist._counts)\n",
    "    _validdist.total = validdist.total\n",
    "\n",
    "    _testdist = FrequencyDistribution()\n",
    "    _testdist._counts = copy(testdist._counts)\n",
    "    _testdist.total = testdist.total\n",
    "\n",
    "    for comp in comps:\n",
    "        _traindist[comp] += 1\n",
    "        _validdist[comp] += 1\n",
    "        _testdist[comp] += 1\n",
    "\n",
    "    trainchange = FrequencyDistribution.compute_chernoff_coeff(_traindist, validdist, alpha=alpha) - FrequencyDistribution.compute_chernoff_coeff(traindist, validdist, alpha=alpha) \\\n",
    "                  + FrequencyDistribution.compute_chernoff_coeff(_traindist, testdist, alpha=alpha) - FrequencyDistribution.compute_chernoff_coeff(traindist, testdist, alpha=alpha)\n",
    "\n",
    "    validchange = FrequencyDistribution.compute_chernoff_coeff(traindist, _validdist, alpha=alpha) - FrequencyDistribution.compute_chernoff_coeff(traindist, validdist, alpha=alpha) \\\n",
    "                  + FrequencyDistribution.compute_chernoff_coeff(_validdist, testdist, alpha=alpha) - FrequencyDistribution.compute_chernoff_coeff(validdist, testdist, alpha=alpha)\n",
    "\n",
    "    testchange = FrequencyDistribution.compute_chernoff_coeff(traindist, _testdist, alpha=alpha) - FrequencyDistribution.compute_chernoff_coeff(traindist, testdist, alpha=alpha) \\\n",
    "                  + FrequencyDistribution.compute_chernoff_coeff(validdist, _testdist, alpha=alpha) - FrequencyDistribution.compute_chernoff_coeff(validdist, testdist, alpha=alpha)\n",
    "\n",
    "    return trainchange, validchange, testchange"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a']\n",
      "(4.557063588286274e-06, 0.07128616642596544, 0.001065680795276904)\n",
      "(-1.0422826546924169e-05, 0.07105075216737256, 0.00046356693626414813)\n",
      "['i']\n",
      "(0.0, 0.0016531718235173105, 0.0018174243917896157)\n",
      "(-2.5238408138950064e-05, 0.001417757564924238, 0.0010820340615026458)\n",
      "['f']\n",
      "(0.29674958590738487, 0.00034284154775237734, 0.00047800600616257615)\n",
      "(0.29672434749924587, 0.0001456918711334465, 0.00012506822682079033)\n",
      "['h']\n",
      "(0.11468305843310449, 0.0, 0.001865738131744269)\n",
      "(0.11465782002496555, -0.00023541425859308074, 0.0011303478014572654)\n",
      "['g']\n",
      "(0.12609010545505056, 0.12943905388013063, 0.0)\n",
      "(0.1260648670469116, 0.12920363962153758, -0.0007353903302870224)\n"
     ]
    }
   ],
   "source": [
    "traindist = FrequencyDistribution()\n",
    "comps = \"a b c d a b c a c d\"\n",
    "comps = \"a a a a a a a a a b c i i\"\n",
    "for comp in comps.split():\n",
    "    traindist[comp] += 100\n",
    "\n",
    "validdist = FrequencyDistribution()\n",
    "comps = \"a b c d a b e f e\"\n",
    "comps = \"b c d d d e e h h f\"\n",
    "# comps = \"a b c d a b c a c d\"\n",
    "\n",
    "for comp in comps.split():\n",
    "    validdist[comp] += 100\n",
    "\n",
    "testdist = FrequencyDistribution()\n",
    "comps = \"a b c d e f g g g h\"\n",
    "comps = \"a e e f f f f g g \"\n",
    "# comps = \"a b c d a b c a c d\"\n",
    "\n",
    "for comp in comps.split():\n",
    "    testdist[comp] += 100\n",
    "\n",
    "comps = \"a\".split()\n",
    "print(comps)\n",
    "print(compute_approx_chernoff_change(comps, traindist, validdist, testdist))\n",
    "print(compute_true_chernoff_chagne(comps, traindist, validdist, testdist))\n",
    "\n",
    "comps = \"i\".split()\n",
    "print(comps)\n",
    "print(compute_approx_chernoff_change(comps, traindist, validdist, testdist))\n",
    "print(compute_true_chernoff_chagne(comps, traindist, validdist, testdist))\n",
    "\n",
    "comps = \"f\".split()\n",
    "print(comps)\n",
    "print(compute_approx_chernoff_change(comps, traindist, validdist, testdist))\n",
    "print(compute_true_chernoff_chagne(comps, traindist, validdist, testdist))\n",
    "\n",
    "comps = \"h\".split()\n",
    "print(comps)\n",
    "print(compute_approx_chernoff_change(comps, traindist, validdist, testdist))\n",
    "print(compute_true_chernoff_chagne(comps, traindist, validdist, testdist))\n",
    "\n",
    "comps = \"g\".split()\n",
    "print(comps)\n",
    "print(compute_approx_chernoff_change(comps, traindist, validdist, testdist))\n",
    "print(compute_true_chernoff_chagne(comps, traindist, validdist, testdist))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_mcd_splits(xs:List, sizes=(0.6, 0.2, 0.2)):\n",
    "    # initialize randomly\n",
    "    dc = DivergenceComputer()\n",
    "\n",
    "    print(\"initializing randomly by selecting 1 random example for each subset\")\n",
    "    xs = [(x[0], x[1], taglisp_to_tree(x[2]) if not isinstance(x[2], Tree) else x[2]) for x in xs]\n",
    "    random.shuffle(xs)\n",
    "    subsets = [[], [], []]\n",
    "    subsets[0].append(xs.pop(0))\n",
    "    subsets[1].append(xs.pop(0))\n",
    "    subsets[2].append(xs.pop(0))\n",
    "\n",
    "    trainstats = FrequencyDistribution()\n",
    "    validstats = FrequencyDistribution()\n",
    "    teststats = FrequencyDistribution()\n",
    "    statses = [trainstats, validstats, teststats]\n",
    "\n",
    "    # update stats\n",
    "    for subset, stats in zip(subsets, [trainstats, validstats, teststats]):\n",
    "        for example in subset:\n",
    "            for comp in dc.extract_compounds(example[2]):\n",
    "                stats[comp] += 1\n",
    "\n",
    "    newxs = []\n",
    "    n = 0\n",
    "    for subset in subsets:\n",
    "        n += len(subset)\n",
    "    while len(xs) > 0:\n",
    "        random.shuffle(xs)\n",
    "        example = xs.pop(-1)\n",
    "        comps = dc.extract_compounds(example[2])\n",
    "        changes = compute_approx_chernoff_change(comps, trainstats, validstats, teststats)\n",
    "        changes = list(zip(changes, range(3)))\n",
    "        bestchoice = sorted(changes, key=lambda x: x[1])[0][1]   # which subset is best\n",
    "        # print(bestchoice)\n",
    "        if len(subsets[bestchoice]) <= sizes[bestchoice] * n:\n",
    "            subsets[bestchoice].append(example)\n",
    "            for comp in comps:\n",
    "                statses[bestchoice][comp] += 1\n",
    "        else:\n",
    "            newxs.append(example)\n",
    "\n",
    "        print(subsets)\n",
    "\n",
    "        if len(xs) == 0:\n",
    "            # updating compound distribution and computing divergences\n",
    "            print(\"updating compound distributions and computing divergences\")\n",
    "            cds = {}\n",
    "            for i, subset in enumerate(subsets):\n",
    "                cds[str(i)] = dc.compute_compound_distribution(subset)\n",
    "            divs = dc._compute_compound_divergences(cds)\n",
    "            print(json.dumps(divs, indent=3))\n",
    "\n",
    "            xs = newxs\n",
    "\n",
    "    # iterate over remaining\n",
    "    # assign to the most fitting subset\n",
    "\n",
    "    return subsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dss = make_mcd_splits(xs[:1000])\n",
    "print(dss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def compute_example_overlap(comps, dist):   # how many of the compounds have already been observed in the given dist\n",
    "    overlap = 0\n",
    "    unoverlap = 0\n",
    "    total = 0\n",
    "    for comp in comps:\n",
    "        if comp in dist and dist[comp] > 0:\n",
    "            overlap += 1\n",
    "        else:\n",
    "            unoverlap += 1\n",
    "        total += 1\n",
    "    return overlap / total, unoverlap / total\n",
    "\n",
    "\n",
    "def compute_example_stats(subsets, cds, dc=None):\n",
    "    print(\"Computing stats for all examples\")\n",
    "    stats = {}\n",
    "    cds = {k: v.tofreqs() for k, v in cds.items()}\n",
    "    for subset in subsets:\n",
    "        for example in tqdm(subset):\n",
    "            eid = example[0]\n",
    "            ecomp = dc.extract_compound_dist(example[2]).tofreqs()\n",
    "            # print(len(ecomp))\n",
    "            stats[eid] = (\n",
    "                FrequencyDistribution.compute_chernoff_coeff(cds[\"0\"], ecomp, alpha=0.01),\n",
    "                FrequencyDistribution.compute_chernoff_coeff(cds[\"1\"], ecomp, alpha=0.01),\n",
    "                FrequencyDistribution.compute_chernoff_coeff(cds[\"2\"], ecomp, alpha=0.01),\n",
    "                FrequencyDistribution.compute_chernoff_coeff(cds[\"0\"], ecomp, alpha=0.9),\n",
    "                FrequencyDistribution.compute_chernoff_coeff(cds[\"1\"], ecomp, alpha=0.9),\n",
    "                FrequencyDistribution.compute_chernoff_coeff(cds[\"2\"], ecomp, alpha=0.9),\n",
    "            )\n",
    "    return stats\n",
    "\n",
    "\n",
    "def make_mcd_splits2(xs:List, sizes=(0.6, 0.2, 0.2), swapsize=10, iters=10):\n",
    "    assert len(sizes) in (3,)\n",
    "    # make random assignments and compute stats\n",
    "    print(\"making random assigments\")\n",
    "    xs = [(x[0], x[1], taglisp_to_tree(x[2]) if not isinstance(x[2], Tree) else x[2]) for x in xs]\n",
    "    random.shuffle(xs)\n",
    "    subsets = []\n",
    "    prev = 0\n",
    "    for i, s in enumerate(sizes):\n",
    "        if i < len(sizes):\n",
    "            c = int(round(s * len(xs))) + prev\n",
    "            subsets.append(xs[prev:c])\n",
    "            prev = c\n",
    "        else:\n",
    "            subsets.append(xs[prev:])\n",
    "\n",
    "    print(\"Computing initial compound distributions and their divergences\")\n",
    "    cds = {}\n",
    "    dc = DivergenceComputer()\n",
    "    for i, subset in enumerate(subsets):\n",
    "        cds[str(i)] = dc.compute_compound_distribution(subset)\n",
    "\n",
    "    divs = dc._compute_compound_divergences(cds)\n",
    "    print(\"Initial compound divergences\")\n",
    "    print(json.dumps(divs, indent=3))\n",
    "\n",
    "    \"\"\"\n",
    "    print(subsets[0][0])\n",
    "    comps = dc.extract_compounds(taglisp_to_tree(subsets[0][0][2]))\n",
    "    print(compute_example_overlap(comps, cds[\"2\"]))\n",
    "    compdist = dc.extract_compound_dist(taglisp_to_tree(subsets[0][0][2]))\n",
    "    print(FrequencyDistribution.compute_chernoff_coeff(cds[\"2\"], compdist, alpha=0.1))\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Iterating\")\n",
    "    # in every iteration, we find for each split the examples that would improve the divergence most and perform one swap\n",
    "    # remove from train set all compounds that are present in test-ood and ood2\n",
    "    # remove from ood2 all compounds that are present in test-ood\n",
    "    # ==> test-ood would contain entirely novel compounds that have not been trained on and have not been validated with\n",
    "    while iters > 0:\n",
    "        stats = compute_example_stats(subsets, cds, dc=dc)   # initial stats\n",
    "\n",
    "        # train --> test-ood\n",
    "        examples = subsets[0]\n",
    "        scored = [(i, stats[examples[i][0]][2]) for i in range(len(examples))]\n",
    "        scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "        scored = [examples[i] for i, score in scored]\n",
    "        traintotest, traintotrain = scored[:swapsize], scored[swapsize:]\n",
    "\n",
    "        # train -> ood2\n",
    "        examples = traintotrain\n",
    "        scored = [(i, stats[examples[i][0]][1]) for i in range(len(examples))]\n",
    "        scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "        scored = [examples[i] for i, score in scored]\n",
    "        traintoood2, traintotrain = scored[:swapsize], scored[swapsize:]\n",
    "\n",
    "        # ood2 -> test-ood\n",
    "        examples = subsets[1]\n",
    "        scored = [(i, stats[examples[i][0]][2]) for i in range(len(examples))]\n",
    "        scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "        scored = [examples[i] for i, score in scored]\n",
    "        ood2totest, ood2toood2 = scored[:swapsize], scored[swapsize:]\n",
    "\n",
    "        # ood2 -> train\n",
    "        examples = ood2toood2\n",
    "        scored = [(i, stats[examples[i][0]][3]) for i in range(len(examples))]\n",
    "        scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "        scored = [examples[i] for i, score in scored]\n",
    "        ood2totrain, ood2toood2 = scored[:swapsize], scored[swapsize:]\n",
    "\n",
    "        # test-ood --> train\n",
    "        examples = subsets[2]\n",
    "        scored = [(i, stats[examples[i][0]][3]) for i in range(len(examples))]\n",
    "        scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "        scored = [examples[i] for i, score in scored]\n",
    "        testtotrain, testtotest = scored[:swapsize], scored[swapsize:]\n",
    "\n",
    "        # test-ood --> ood2\n",
    "        examples = testtotest\n",
    "        scored = [(i, stats[examples[i][0]][4]) for i in range(len(examples))]\n",
    "        scored = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "        scored = [examples[i] for i, score in scored]\n",
    "        testtoood2, testtotest = scored[:swapsize], scored[swapsize:]\n",
    "\n",
    "        subsets = [traintotrain + ood2totrain + testtotrain,\n",
    "                   ood2toood2 + traintoood2 + testtoood2,\n",
    "                   testtotest + traintotest + ood2totest]\n",
    "\n",
    "\n",
    "        # updating compound distribution and computing divergences\n",
    "        print(\"updating compound distributions and computing divergences\")\n",
    "        cds = {}\n",
    "        for i, subset in enumerate(subsets):\n",
    "            cds[str(i)] = dc.compute_compound_distribution(subset)\n",
    "        divs = dc._compute_compound_divergences(cds)\n",
    "        print(json.dumps(divs, indent=3))\n",
    "\n",
    "        iters -= 1\n",
    "\n",
    "\n",
    "    return cds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing randomly by selecting 1 random example for each subset\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-85-9224ddda5d94>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmake_mcd_splits\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mxs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m1000\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-83-889969cb3e3b>\u001B[0m in \u001B[0;36mmake_mcd_splits\u001B[1;34m(xs, sizes)\u001B[0m\n\u001B[0;32m     32\u001B[0m         \u001B[0mchanges\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchanges\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[0mbestchoice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msorted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchanges\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m   \u001B[1;31m# which subset is best\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 34\u001B[1;33m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msubsets\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbestchoice\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0msizes\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mn\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     35\u001B[0m             \u001B[0msubsets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mexample\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "dss = make_mcd_splits(xs[:1000])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "### len(dss[0]), len(dss[1]), len(dss[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute '_counts'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-985f04bf759f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdss\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_counts\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute '_counts'"
     ]
    }
   ],
   "source": [
    "dss[0]._counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}